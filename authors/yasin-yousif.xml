<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Robot Learning by Example (Posts by Yasin Yousif)</title><link>https://engyasin.github.io/</link><description></description><atom:link href="https://engyasin.github.io/authors/yasin-yousif.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2025 &lt;a href="mailto:yy33@tu-clausthal.de"&gt;Yasin Yousif&lt;/a&gt; </copyright><lastBuildDate>Wed, 25 Jun 2025 11:04:51 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><link>https://engyasin.github.io/posts/the-reinforcement-learning-algorithmic-landscape/</link><dc:creator>Yasin Yousif</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;strong&gt;NOTE: a book draft (Feedback is appreciated)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Deep Reinforcement Learning is a branch of machine learning, gaining rapid traction recently as an efficient approach to skills acquisition by machines, across diverse fields of applications. From optimizing advertising placement to enabling robotic manipulation and through refining Large Language Models responses, its potential is predicted to be immense. The field encompasses a rich variety of algorithms, spanning model-based and model-free techniques, policy gradients, and Q-learning methods. This dynamic landscape can be daunting for newcomers, even those with a foundation in supervised learning. In this post we provide a comprehensive overview, offering both a high-level perspective as well as a detailed examination of the underlying mathematical derivations and algorithms specifics. We’re also including full benchmarking results for all methods in both discrete and continuous environments, along with some unsolved questions and recommended readings for the interested reader.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://engyasin.github.io/posts/the-reinforcement-learning-algorithmic-landscape/"&gt;Read more…&lt;/a&gt; (36 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>benchmarking</category><category>guide</category><category>MujoCo</category><category>reinforcement learning</category><category>tutorial</category><guid>https://engyasin.github.io/posts/the-reinforcement-learning-algorithmic-landscape/</guid><pubDate>Sun, 11 May 2025 16:34:24 GMT</pubDate></item><item><link>https://engyasin.github.io/posts/immerse-yourself-in-reinforcement-learning-and-robotics-with-mujoco/</link><dc:creator>Yasin Yousif</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;em&gt;MujoCo is a physics simulator for robotics research developed by Google DeepMind and written in C++ with a Python API. The advantage of using MujoCo is due to its various implemented models along with full dynamic and physics properties, such as friction, inertia, elasticity, etc. This realism allows researchers to rigorously test reinforcement learning algorithms in simulations before deployment, mitigating risks associated with real-world applications. Simulating exact replicas of robot manipulators becomes particularly valuable, enabling training in a safe virtual environment and seamless transition to production. Notable examples include open-source models for popular brands like ALOHA, FRANKA, and KUKA readily available within MujoCo.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://engyasin.github.io/posts/immerse-yourself-in-reinforcement-learning-and-robotics-with-mujoco/"&gt;Read more…&lt;/a&gt; (12 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>MujoCo</category><category>reinforcement learning</category><category>robotics</category><category>simulation</category><category>tutorial</category><guid>https://engyasin.github.io/posts/immerse-yourself-in-reinforcement-learning-and-robotics-with-mujoco/</guid><pubDate>Wed, 05 Feb 2025 19:10:29 GMT</pubDate></item><item><link>https://engyasin.github.io/posts/hands-on-imitation-learning/</link><dc:creator>Yasin Yousif</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;em&gt;An overview of the most prominent imitation learning methods with tests on a grid environment&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Reinforcement learning is one branch of machine learning concerned with learning by guidance of scalar signals (rewards); in contrast to supervised learning, which needs full labels of  the target variable.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://engyasin.github.io/posts/hands-on-imitation-learning/"&gt;Read more…&lt;/a&gt; (18 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>deep-learning</category><category>reinforcement learning</category><category>review</category><guid>https://engyasin.github.io/posts/hands-on-imitation-learning/</guid><pubDate>Sat, 07 Sep 2024 22:53:52 GMT</pubDate></item><item><link>https://engyasin.github.io/posts/tracking-my-working-times-for-804-days/</link><dc:creator>Yasin Yousif</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;em&gt;As a student or knowledge worker, time management is essential for achieving success. However, organizing one's schedule can be challenging, for instance one is faced with the problem of distributing work and rest times in optimal time windows. To address this issue, analyzing previous working schedules of an individual may provide useful recommendations for him.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://engyasin.github.io/posts/tracking-my-working-times-for-804-days/"&gt;Read more…&lt;/a&gt; (7 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>GAM</category><category>productivity</category><category>tips</category><guid>https://engyasin.github.io/posts/tracking-my-working-times-for-804-days/</guid><pubDate>Sun, 14 Apr 2024 11:25:04 GMT</pubDate></item><item><link>https://engyasin.github.io/posts/why-deep-learning-sucks/</link><dc:creator>Yasin Yousif</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;em&gt;After spending some years studying and using deep learning, I always suffered from the difficulty of debugging errors, or setting hyperparameters. As a researcher this can not only waste additional time, but also money and resources. In this article, we will demonstrate how traditional rule-based methods have a hidden edge (beside simplicity) in solving complex problems that require automation.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://engyasin.github.io/posts/why-deep-learning-sucks/"&gt;Read more…&lt;/a&gt; (3 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>ai</category><category>deep-learning</category><category>opinion</category><guid>https://engyasin.github.io/posts/why-deep-learning-sucks/</guid><pubDate>Tue, 09 Jan 2024 11:49:14 GMT</pubDate></item><item><title>The unexpected winter of Artifical Intelligence</title><link>https://engyasin.github.io/posts/the-unexpected-winter-of-artifical-intelligence/</link><dc:creator>Yasin Yousif</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;em&gt;Nowadays, everyone is exicted the latest trends in AI applications, like ChatGPT, self-driving cars, Image synthesis, etc. This overhype is not new, it happened before in the first AI winter in the 1980s. Some warn againt it, because it may cause dispointment and even a new AI winter. But here I will talk about the bottelneck of AI research that I come across in my work. It may be not be called a winter, but it's difinitely will cause a slow down in the field.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://engyasin.github.io/posts/the-unexpected-winter-of-artifical-intelligence/"&gt;Read more…&lt;/a&gt; (3 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>ai</category><category>deep-learning</category><category>opinion</category><guid>https://engyasin.github.io/posts/the-unexpected-winter-of-artifical-intelligence/</guid><pubDate>Sun, 05 Mar 2023 06:13:36 GMT</pubDate></item><item><link>https://engyasin.github.io/posts/train-your-deep-neural-network-faster-with-automatic-mixed-precision/</link><dc:creator>Yasin Yousif</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;em&gt;Have you been working on deep learning model with big size and wandered how to squeeze every possibility to save your time? or maybe you have the best GPU hardware but still find the speed too slow. Well, look at the bright side. This means you still have room for improvment :)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://engyasin.github.io/posts/train-your-deep-neural-network-faster-with-automatic-mixed-precision/"&gt;Read more…&lt;/a&gt; (2 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>deep-learning</category><category>pytorch</category><category>tips</category><guid>https://engyasin.github.io/posts/train-your-deep-neural-network-faster-with-automatic-mixed-precision/</guid><pubDate>Fri, 23 Sep 2022 14:53:19 GMT</pubDate></item></channel></rss>